# 测试验证模块 - 产品需求文档

> **项目**: AI超级个体开发助手
> **版本**: v1.0
> **迭代**: Iteration 1
> **日期**: 2025-12-14
> **模块**: 测试验证模块
> **状态**: 需求已确认

---

<!--
章节ID规范说明：
- 格式：{#prd-测试验证-[章节编号]}
- 必须标注ID的章节：功能点清单、数据模型、用户故事与验收标准
-->

## 一、产品愿景

### 1.1 一句话描述

提供完整的测试体系，从单元测试到混沌测试，确保系统质量和可靠性。

### 1.2 核心定位

| 维度         | 定义                                    |
| ------------ | --------------------------------------- |
| **产品类型** | 测试自动化引擎 + 测试用例生成器         |
| **目标平台** | Node.js + 测试框架（Jest/Vitest等）     |
| **用户定位** | AI助手（生成测试）+ 独立开发者（审阅） |
| **核心价值** | 自动生成测试用例，覆盖率100%，质量保证  |

### 1.3 技术定位

- **部署方式**：测试代码嵌入项目源码（src/、tests/目录）
- **集成方式**：AI生成测试代码 + 自动执行测试
- **数据持久化**：测试结果记录在state.json的changeHistory

---

## 二、目标用户

### 2.1 用户画像

```yaml
名称: AI助手（主要用户）+ 独立开发者（次要用户）

AI助手特征:
  - 需要明确的测试生成依据（文档、代码）
  - 需要自动执行测试并检测覆盖率
  - 需要测试失败时执行根因分析
  - 需要生成测试文档供人工审批

独立开发者特征:
  - 需要确保代码质量（覆盖率100%）
  - 需要快速识别测试失败的原因
  - 需要审批测试方案（E2E、性能、混沌）
  - 需要测试数据可维护

典型场景:
  - Implementation阶段：AI生成单元测试和集成测试
  - Testing阶段：AI生成E2E、性能、混沌测试
  - 测试失败：AI分析根因并生成修复任务
  - 覆盖率不足：AI生成缺失测试用例清单

核心诉求:
  - 测试自动生成，无需手写
  - 覆盖率强制100%（单元测试）
  - 测试失败根因分析准确
  - 测试方案可审批，可定制
```

### 2.2 用户痛点

| 痛点          | 描述           | 影响           | 解决方案       |
| ------------- | -------------- | -------------- | -------------- |
| **P1: 测试覆盖率不足** | 手写测试容易遗漏代码路径 | 潜在Bug未被发现 | 强制100%覆盖率，AI自动补充缺失测试 |
| **P2: 测试失败难定位** | 不知道是代码问题还是需求问题 | 修复方向错误 | 分层根因分析（测试用例 → 代码 → 架构 → 需求） |
| **P3: 测试数据维护难** | 测试数据散落在代码中 | 修改成本高 | 集中管理测试数据（tests/fixtures/*.json） |
| **P4: 测试场景不全面** | 只测试正常流程，忽略异常 | 边界case未覆盖 | 混沌测试（通用测试经验库） |

---

## 三、功能架构

### 3.1 系统架构图

```
测试阶段划分
  ├─ Implementation阶段
  │   ├─ 单元测试（基于架构文档生成，覆盖率100%）
  │   └─ 集成测试（基于integrationPoints + @integration标注）
  └─ Testing阶段
      ├─ E2E测试（基于PRD验收标准生成）
      ├─ 性能测试（基于PRD性能要求生成）
      └─ 混沌测试（基于通用测试经验库生成）
          ↓
测试用例生成
  ├─ 读取生成依据（文档、代码、经验库）
  ├─ AI生成测试代码
  └─ 保存到对应目录
          ↓
测试执行
  ├─ 运行测试
  ├─ 检测覆盖率
  └─ 生成测试报告
          ↓
【如果测试失败】
  ├─ 根因分析（分层分析）
  ├─ 生成修复任务链
  └─ 人工确认回滚阶段
          ↓
【如果覆盖率不足】
  ├─ AI生成缺失测试用例清单
  ├─ 人工审批清单
  └─ AI补充测试代码

完整架构设计详见：docs/architecture/iteration-1/00-系统架构总览.md
```

### 3.2 模块划分

| 模块名        | 职责               | 实现方式           |
| ------------- | ------------------ | ------------------ |
| **测试生成模块** | 基于文档/代码生成测试用例 | AI推理 + 模板 |
| **测试执行模块** | 运行测试并收集结果 | Jest/Vitest等测试框架 |
| **覆盖率检测模块** | 检测单元测试覆盖率 | Istanbul/c8等覆盖率工具 |
| **根因分析模块** | 测试失败时分层分析根因 | AI推理 + 机械性检查 |
| **测试数据管理** | 管理测试数据文件 | tests/fixtures/*.json |

---

## 四、核心功能设计

### 4.1 功能点清单 {#prd-测试验证-功能清单}

**详细功能设计详见**：docs/architecture/iteration-1/02-命令设计.md

| 功能点                      | 描述                           | 触发时机                          |
| --------------------------- | ------------------------------ | --------------------------------- |
| 单元测试生成                 | 基于命令设计+数据模型生成      | Implementation阶段，每个模块实现后 |
| 集成测试生成                 | 基于integrationPoints生成      | Implementation阶段，每个模块实现后 |
| E2E测试生成                  | 基于PRD验收标准生成            | Testing阶段，第1个审批点 |
| 性能测试生成                 | 基于PRD性能要求生成            | Testing阶段，第2个审批点 |
| 混沌测试生成                 | 基于通用测试经验库生成         | Testing阶段，第3个审批点 |
| 覆盖率检测                   | 检测单元测试覆盖率是否100%     | 单元测试执行后 |
| 缺失测试用例清单生成         | 生成未覆盖代码的测试用例建议   | 覆盖率不足时 |
| 测试失败根因分析             | 分层分析：测试 → 代码 → 架构 → 需求 | 测试失败时 |
| 测试数据生成                 | 基于数据模型生成Mock数据       | 测试生成时 |

### 4.2 数据模型 {#prd-测试验证-数据模型}

#### 核心数据结构（概览）

**测试目录结构**

```
项目根目录/
├── src/
│   └── [模块名]/
│       └── __tests__/
│           ├── *.unit.test.ts       # 单元测试
│           └── *.integration.test.ts # 集成测试
└── tests/
    ├── e2e/
    │   └── *.e2e.test.ts            # E2E测试
    ├── performance/
    │   └── *.perf.test.ts           # 性能测试
    ├── chaos/
    │   └── *.chaos.test.ts          # 混沌测试
    └── fixtures/
        ├── users.json               # 用户测试数据
        ├── orders.json              # 订单测试数据
        └── edge-cases.json          # 边界case数据
```

**state.json - phases.testing字段**

```json
{
  "phases": {
    "testing": {
      "status": "in_progress",
      "documents": {
        "E2E测试计划": {
          "status": "approved",
          "approvedAt": "2025-12-14T10:00:00Z"
        },
        "性能测试方案": {
          "status": "approved",
          "approvedAt": "2025-12-14T11:00:00Z"
        },
        "混沌测试方案": {
          "status": "approved",
          "approvedAt": "2025-12-14T12:00:00Z"
        }
      },
      "testResults": {
        "unit": {
          "total": 120,
          "passed": 120,
          "failed": 0,
          "coverage": 100
        },
        "integration": {
          "total": 45,
          "passed": 45,
          "failed": 0
        },
        "e2e": {
          "total": 30,
          "passed": 30,
          "failed": 0
        },
        "performance": {
          "total": 10,
          "passed": 10,
          "failed": 0
        },
        "chaos": {
          "total": 15,
          "passed": 15,
          "failed": 0
        }
      }
    }
  }
}
```

**关键字段说明**：

| 字段名      | 类型     | 说明                   | 必填 |
| ----------- | -------- | ---------------------- | ---- |
| `testResults` | object | 各类测试的执行结果 | 是 |
| `testResults[].coverage` | number | 覆盖率百分比（仅单元测试） | 是 |
| `testResults[].passed` | number | 通过的测试用例数 | 是 |
| `testResults[].failed` | number | 失败的测试用例数 | 是 |

**完整数据模型详见**：docs/architecture/iteration-1/03-数据模型设计.md

### 4.3 核心工作流

**工作流1：Implementation阶段单元测试生成**

```
AI实现模块代码完成
  ↓
【步骤1】AI读取架构文档
  - 命令设计.md → 了解接口定义、输入输出、错误处理
  - 数据模型设计.md → 了解数据结构、字段验证规则
  - 00-系统架构总览.md → 了解模块职责
  ↓
【步骤2】AI生成单元测试用例
  - 正常流程测试（基于命令设计的输入输出）
  - 边界条件测试（基于数据模型的字段验证）
  - 错误处理测试（基于命令设计的错误类型）
  ↓
【步骤3】AI执行单元测试
  npm test -- src/[模块名]/__tests__/*.unit.test.ts
  ↓
【步骤4】AI检测覆盖率
  npm test -- --coverage
  ↓
【步骤5】判断覆盖率是否达到100%
  ├─ 达标 → 继续下一步
  └─ 不达标 → 生成缺失测试用例清单
      ↓
      提交人工审批
      ↓
      审批通过 → AI补充测试代码
      ↓
      重新检测覆盖率

完整工作流设计详见：CLAUDE.md（第八节 - 测试规范）
```

**工作流2：Testing阶段E2E测试生成**

```
用户执行：/start-testing
  ↓
【步骤1】AI读取PRD中的用户故事和验收标准
  ↓
【步骤2】AI生成E2E测试计划文档
  - 为每个用户故事生成测试场景
  - 测试场景包含：测试步骤、断言点、预期结果
  - 断言点直接对应PRD的验收标准
  ↓
【步骤3】AI保存测试计划文档
  保存到：docs/testing/iteration-1/E2E测试计划.md
  ↓
【步骤4】AI提交人工审批
  提示："E2E测试计划已生成，请审批"
  ↓
用户审批
  ├─ 通过 → 继续
  └─ 拒绝 → AI根据意见重新生成测试计划
  ↓
【步骤5】AI基于审批后的测试计划生成测试代码
  保存到：tests/e2e/*.e2e.test.ts
  ↓
【步骤6】AI执行E2E测试
  npm test -- tests/e2e/
  ↓
【步骤7】判断测试是否全部通过
  ├─ 通过 → 进入性能测试阶段
  └─ 失败 → 执行根因分析
```

**工作流3：测试失败根因分析**

```
E2E测试失败
  ↓
【步骤1】AI分层分析
  层1: 测试用例问题？
    → 检查测试用例的断言逻辑是否正确
    → 对比测试用例与PRD验收标准
    → 结论：测试用例正确/错误

  层2: 代码Bug？
    → 检查代码实现是否符合架构设计
    → 对比代码与命令设计文档
    → 结论：代码实现正确/错误

  层3: 架构设计问题？
    → 检查架构设计是否完整
    → 分析是否缺少必要机制（如事务管理）
    → 结论：架构设计正确/有缺陷

  层4: 需求问题？
    → 检查PRD验收标准是否合理
    → 分析验收标准是否与业务目标一致
    → 结论：需求正确/有问题
  ↓
【步骤2】AI生成根因分析报告
  - 根本原因：[层X的具体问题]
  - 建议回滚阶段：[requirements/architecture/implementation]
  - 依据：[分析依据]
  ↓
【步骤3】AI生成修复任务链
  - 任务1: 修改[文档/代码]（需要人工审批/AI实现）
  - 任务2: 修改[文档/代码]
  - 任务3: 重新执行测试
  ↓
【步骤4】AI提交人工确认
  提示："是否同意回滚到[阶段]并执行修复任务？"
  ↓
用户确认
  ├─ 同意 → 执行修复任务链
  └─ 拒绝，指定真实根因 → AI根据反馈重新分析
```

**工作流4：混沌测试生成**

```
性能测试通过
  ↓
【步骤1】AI基于通用测试经验库生成混沌测试方案
  经验库包含：
    - 边界条件：空值、null、undefined、最大值、最小值
    - 并发冲突：竞态条件、死锁、数据一致性
    - 资源耗尽：内存溢出、连接池耗尽、磁盘空间满
    - 网络故障：超时、断连、延迟、丢包
    - 依赖失败：数据库故障、第三方API失败
  ↓
【步骤2】AI生成混沌测试方案文档
  - 测试场景1：数据库连接失败
    - 故障注入：模拟数据库连接中断
    - 预期系统行为：自动重试、返回友好错误、记录日志
    - 恢复验证：数据库恢复后系统正常
  - 测试场景2：并发创建订单
    - 故障注入：1000个并发请求
    - 预期系统行为：库存准确、订单号唯一、无死锁
  ↓
【步骤3】AI保存测试方案文档
  保存到：docs/testing/iteration-1/混沌测试方案.md
  ↓
【步骤4】AI提交人工审批
  ↓
审批通过
  ↓
【步骤5】AI生成混沌测试代码
  保存到：tests/chaos/*.chaos.test.ts
  ↓
【步骤6】AI执行混沌测试
```

---

## 五、用户故事与验收标准 {#prd-测试验证-验收标准}

### 5.1 用户故事清单

#### 用户视角（面向AI助手）

**故事 1：AI生成单元测试（基于架构文档）**
```
作为AI助手，我想基于命令设计和数据模型自动生成单元测试，以便覆盖所有代码路径。

验收标准：
  - [ ] AI读取命令设计.md，提取接口定义、输入输出、错误处理
  - [ ] AI读取数据模型设计.md，提取数据结构、字段验证规则
  - [ ] AI生成测试用例（正常流程、边界条件、错误处理）
  - [ ] AI执行测试并检测覆盖率
  - [ ] 覆盖率达到100%后继续，否则生成缺失测试用例清单
```

**故事 2：AI生成集成测试（基于integrationPoints）**
```
作为AI助手，我想基于state.json的integrationPoints生成集成测试，以便验证模块间交互。

验收标准：
  - [ ] AI读取state.json.moduleDependencies[模块].integrationPoints
  - [ ] AI为每个集成点生成集成测试（验证调用、验证返回值、验证错误处理）
  - [ ] AI执行集成测试
  - [ ] 测试通过后继续，失败则执行根因分析
```

**故事 3：AI生成E2E测试计划（基于PRD验收标准）**
```
作为AI助手，我想基于PRD的验收标准生成E2E测试计划，以便覆盖所有用户故事。

验收标准：
  - [ ] AI读取PRD中的用户故事列表
  - [ ] AI读取每个用户故事的验收标准
  - [ ] AI为每个用户故事生成E2E测试场景（测试步骤、断言点）
  - [ ] 断言点直接对应PRD的验收标准（引用式设计）
  - [ ] AI生成E2E测试计划文档，提交人工审批
```

**故事 4：AI生成性能测试方案（基于PRD性能要求）**
```
作为AI助手，我想基于PRD的性能要求生成性能测试方案，以便验证系统性能指标。

验收标准：
  - [ ] AI读取PRD中的性能要求（响应时间、并发数、吞吐量）
  - [ ] AI生成性能测试场景（负载测试、压力测试、稳定性测试）
  - [ ] AI明确性能指标和测试数据量
  - [ ] AI生成性能测试方案文档，提交人工审批
```

**故事 5：AI生成混沌测试方案（基于通用测试经验库）**
```
作为AI助手，我想基于通用测试经验库生成混沌测试方案，以便验证系统鲁棒性。

验收标准：
  - [ ] AI使用通用测试经验库（边界条件、并发冲突、资源耗尽、网络故障、依赖失败）
  - [ ] AI生成混沌测试场景（故障注入、预期行为、恢复验证）
  - [ ] AI明确每个场景的故障类型和验证标准
  - [ ] AI生成混沌测试方案文档，提交人工审批
```

**故事 6：AI检测覆盖率并生成缺失测试用例清单**
```
作为AI助手，我想在覆盖率不足时生成缺失测试用例清单，以便人工审批后补充测试。

验收标准：
  - [ ] AI执行单元测试并检测覆盖率
  - [ ] 如覆盖率< 100%，AI生成缺失测试用例清单
  - [ ] 清单包含：文件路径、未覆盖行数、代码逻辑、建议测试用例
  - [ ] AI提交清单给人工审批
  - [ ] 审批通过后，AI补充测试代码
```

**故事 7：AI执行测试失败根因分析**
```
作为AI助手，我想在测试失败时执行分层分析，以便找到真实根因并生成修复任务。

验收标准：
  - [ ] AI执行分层分析（测试用例 → 代码 → 架构 → 需求）
  - [ ] AI生成根因分析报告（根本原因、建议回滚阶段、分析依据）
  - [ ] AI生成修复任务链（自上而下：PRD → 架构 → 代码）
  - [ ] AI提交人工确认："是否同意回滚到[阶段]？"
```

**故事 8：AI基于数据模型生成测试数据**
```
作为AI助手，我想基于数据模型自动生成Mock测试数据，以便测试用例使用。

验收标准：
  - [ ] AI读取数据模型设计.md
  - [ ] AI生成有效数据（符合字段类型和验证规则）
  - [ ] AI生成无效数据（边界case、异常数据）
  - [ ] AI保存测试数据到tests/fixtures/*.json
  - [ ] 测试用例可导入并使用测试数据
```

#### 用户视角（面向独立开发者）

**故事 9：审批E2E测试计划**
```
作为独立开发者，我想审阅AI生成的E2E测试计划，以便确认测试场景完整且符合业务需求。

验收标准：
  - [ ] 对照PRD验收标准，检查E2E测试场景是否覆盖所有用户故事
  - [ ] 检查测试步骤是否清晰、可执行
  - [ ] 检查断言点是否与验收标准一致
  - [ ] 如发现遗漏或错误，拒绝审批并提供修改意见
  - [ ] 审批通过后，AI生成测试代码
```

**故事 10：审批缺失测试用例清单**
```
作为独立开发者，我想审阅AI生成的缺失测试用例清单，以便确认补充的测试用例必要且准确。

验收标准：
  - [ ] 检查清单中的未覆盖代码行是否真的需要测试
  - [ ] 检查建议的测试用例是否合理
  - [ ] 可以删除不必要的测试用例（如不可达代码）
  - [ ] 审批通过后，AI补充测试代码
```

**故事 11：确认测试失败根因**
```
作为独立开发者，我想在AI分析测试失败根因后确认结论，以便确保修复方向正确。

验收标准：
  - [ ] 阅读AI的根因分析报告
  - [ ] 判断AI的分析是否准确
  - [ ] 如同意，确认回滚到建议的阶段
  - [ ] 如不同意，手动指定真实根因和回滚阶段
  - [ ] AI根据确认结果执行修复任务
```

#### 系统视角（面向功能模块）

**故事 12：渐进式测试执行**
```
作为系统，我需要按照正确顺序执行测试，以便在早期发现问题避免浪费时间。

验收标准：
  - [ ] Implementation阶段：单元测试 → 集成测试（逐模块）
  - [ ] Testing阶段：E2E测试 → 性能测试 → 混沌测试（渐进式）
  - [ ] 前一个测试类型通过后才执行下一个
  - [ ] 任何阶段测试失败，暂停并执行根因分析
```

**故事 13：测试代码组织**
```
作为系统，我需要按照约定组织测试代码，以便易于维护和查找。

验收标准：
  - [ ] 单元测试：src/[模块名]/__tests__/*.unit.test.ts
  - [ ] 集成测试：src/[模块名]/__tests__/*.integration.test.ts
  - [ ] E2E测试：tests/e2e/*.e2e.test.ts
  - [ ] 性能测试：tests/performance/*.perf.test.ts
  - [ ] 混沌测试：tests/chaos/*.chaos.test.ts
  - [ ] 测试数据：tests/fixtures/*.json
```

**故事 14：Git提交策略**
```
作为系统，我需要按阶段提交测试代码，以便Git历史清晰可追溯。

验收标准：
  - [ ] Implementation阶段：业务代码 + 单元测试 + 集成测试 → 1次commit
  - [ ] Testing阶段：E2E测试文档 + 代码 → 1次commit
  - [ ] Testing阶段：性能测试文档 + 代码 → 1次commit
  - [ ] Testing阶段：混沌测试文档 + 代码 → 1次commit
  - [ ] Commit message符合Conventional Commits规范
```

### 5.2 边界条件与异常处理

| 场景                 | 期望行为               | 错误处理               |
| -------------------- | ---------------------- | ---------------------- |
| **测试框架未安装**   | 拒绝执行，提示安装依赖 | 错误码500，提示"请先安装Jest/Vitest" |
| **测试超时**         | 标记测试失败，记录超时 | 默认超时30秒，可配置 |
| **测试数据文件缺失** | 警告但继续执行（使用默认数据） | 警告"测试数据文件不存在：[路径]" |
| **覆盖率检测失败**   | 降级到不检测覆盖率 | 警告"覆盖率检测失败，跳过检查" |
| **根因分析失败**     | 提示人工判断 | 提示"无法自动分析根因，请人工判断" |

---

## 六、非功能需求

### 6.1 性能要求

| 指标             | 要求                   | 备注               |
| ---------------- | ---------------------- | ------------------ |
| **单元测试执行时间** | < 30秒（所有单元测试） | 项目规模< 10万行代码 |
| **E2E测试执行时间** | < 5分钟（所有E2E测试） | 30个测试场景 |
| **覆盖率检测时间** | < 10秒 | 基于Istanbul/c8 |

### 6.2 可靠性要求

- **容错性**：测试执行失败时不影响代码和文档
- **数据一致性**：测试结果记录到state.json.phases.testing.testResults
- **可恢复性**：测试失败后可重新执行

### 6.3 可维护性要求

- **日志**：记录所有测试执行历史（测试类型、执行时间、结果）
- **监控**：覆盖率趋势监控（是否下降）
- **可测试性**：测试代码本身需要可读、可维护

### 6.4 准确性要求

- **测试覆盖率准确性**：覆盖率检测准确率100%（基于工具）
- **根因分析准确性**：AI推理准确率目标80%（用户最终确认）
- **测试用例质量**：生成的测试用例需真正验证功能（非形式化测试）

---

## 七、技术约束与依赖

### 7.1 技术栈要求

- **测试框架**：Jest / Vitest（推荐Vitest）
- **覆盖率工具**：Istanbul / c8
- **E2E测试**：Playwright / Puppeteer（如需浏览器测试）
- **性能测试**：k6 / autocannon
- **测试数据格式**：JSON

### 7.2 兼容性要求

- **项目规模**：支持< 10万行代码的项目
- **语言**：主要支持TypeScript/JavaScript
- **测试框架版本**：兼容Jest 29+ / Vitest 1.0+

### 7.3 依赖关系

| 依赖模块       | 依赖原因                     | 集成方式           |
| -------------- | ---------------------------- | ------------------ |
| **文档模板模块** | 读取测试文档模板 | 读取.solodev/templates/testing/ |
| **影响分析模块** | 测试失败时触发根因分析 | 接收测试失败事件 |
| **状态管理模块** | 记录测试结果到state.json | 写入state.json |
| **Git集成模块** | 测试代码自动提交 | Git命令调用 |

**完整依赖关系详见**：docs/architecture/iteration-1/04-模块集成设计.md

---

## 八、迭代规划

### 8.1 Iteration 1 (MVP)

- **目标**：实现完整测试体系（单元、集成、E2E、性能、混沌）
- **功能范围**：
  - 单元测试生成（基于架构文档，覆盖率100%）
  - 集成测试生成（基于integrationPoints）
  - E2E测试生成（基于PRD验收标准，3次审批）
  - 性能测试生成（基于PRD性能要求）
  - 混沌测试生成（基于通用测试经验库）
  - 覆盖率检测和缺失测试用例清单生成
  - 测试失败根因分析（分层分析）
- **验收标准**：
  - 单元测试覆盖率100%
  - E2E测试覆盖所有用户故事
  - 根因分析准确率≥70%

### 8.2 Iteration 2（未来增强）

- **目标**：增加测试回归、测试优先级、测试并行
- **功能范围**：
  - 回归测试（代码变更后自动运行相关测试）
  - 测试优先级（P0测试先执行）
  - 测试并行执行（缩短测试时间）
  - 测试覆盖率趋势监控
  - 可视化测试报告
- **验收标准**：
  - 回归测试准确识别相关测试
  - 测试执行时间缩短50%（并行）
  - 测试报告可视化、可导出

---

**文档版本历史**

| 版本  | 日期       | 修改内容               | 修改人 |
| ----- | ---------- | ---------------------- | ------ |
| v1.0  | 2025-12-14 | 初始版本，需求确认完成 | Claude AI |
