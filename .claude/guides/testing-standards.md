# 测试规范指南（Testing Standards）

> 本指南详细说明测试策略、覆盖率要求、测试用例生成规范（testing阶段必读）

---

## 一、测试阶段划分

本项目的测试分为两个阶段：

### Implementation阶段测试

**单元测试**：
- **生成依据**：命令设计.md + 数据模型设计.md + 系统架构总览.md
- **覆盖率要求**：100%（强制）
- **执行时机**：每个模块实现完成后立即执行
- **审批要求**：无需人工审批，AI自动生成
- **存放位置**：`src/[模块名]/__tests__/*.unit.test.ts`

**集成测试**：
- **生成依据**：state.json的integrationPoints + 代码中的@integration标注
- **执行时机**：每个模块实现完成后执行
- **审批要求**：无需人工审批，AI自动生成
- **存放位置**：`src/[模块名]/__tests__/*.integration.test.ts`

### Testing阶段测试

**E2E测试**：
- **生成依据**：PRD的验收标准 + 用户故事
- **生成流程**：AI生成测试计划 → 人工审批 → AI生成测试代码
- **执行时机**：Testing阶段开始时，第1个执行
- **存放位置**：`tests/e2e/*.e2e.test.ts`

**性能测试**：
- **生成依据**：PRD的性能要求（响应时间、并发数、吞吐量）
- **生成流程**：AI生成测试方案 → 人工审批 → AI生成测试代码
- **执行时机**：E2E测试通过后执行
- **存放位置**：`tests/performance/*.perf.test.ts`

**混沌测试**：
- **生成依据**：AI通用测试经验库（边界条件、并发冲突、资源耗尽、网络故障等）
- **生成流程**：AI生成测试方案 → 人工审批 → AI生成测试代码
- **执行时机**：性能测试通过后执行
- **存放位置**：`tests/chaos/*.chaos.test.ts`

---

## 二、单元测试覆盖率要求

**强制要求：100%覆盖率**

### 验证流程

```
模块实现完成
  ↓
执行单元测试
  ↓
检测覆盖率
  ↓
【如果未达标】
  ├─ AI生成缺失的测试用例清单
  ├─ 提交给人工审批
  ├─ 人工审批通过后，AI补充测试代码
  └─ 重新检测覆盖率
  ↓
【达标】继续下一个模块
```

---

## 三、测试用例自动生成规范

### Implementation阶段：单元测试生成

**步骤1**：读取架构文档
- 命令设计.md → 接口定义、输入输出、错误处理
- 数据模型设计.md → 数据结构、字段验证规则
- 系统架构总览.md → 模块职责、依赖关系

**步骤2**：基于架构文档生成测试用例
- 正常流程测试
- 错误处理测试
- 边界条件测试

**步骤3**：验证覆盖率
- 执行测试
- 检测覆盖率
- 未达标则补充测试用例

### Implementation阶段：集成测试生成

**步骤1**：读取integrationPoints
- 从state.json获取模块间集成点定义

**步骤2**：生成集成测试
- 验证是否正确调用外部模块
- 验证参数传递是否正确
- 验证错误处理是否正确

### Testing阶段：E2E测试生成

**步骤1**：AI生成测试文档
- 读取PRD的用户故事和验收标准
- 生成E2E测试计划.md

**步骤2**：人工审批测试计划

**步骤3**：AI生成测试代码
- 基于审批后的计划生成完整测试代码

### Testing阶段：混沌测试生成

**AI测试经验库包含**：
- **边界条件**：空值、null、undefined、最大值、最小值、特殊字符
- **并发冲突**：竞态条件、死锁、数据一致性
- **资源耗尽**：内存溢出、连接池耗尽、磁盘空间满
- **网络故障**：超时、断连、延迟、丢包
- **依赖失败**：数据库故障、第三方API失败、消息队列失败

---

## 四、测试数据管理规范

### 数据来源

**主要来源**：AI基于数据模型自动生成Mock数据

**补充来源**：人工添加边界case和特殊场景数据

### 数据组织

```
tests/fixtures/
├── users.json          # 用户测试数据
├── orders.json         # 订单测试数据
├── products.json       # 产品测试数据
└── edge-cases.json     # 通用边界case
```

---

## 五、测试失败根因分析流程

当测试失败时，AI执行分层分析：

```
测试失败
  ↓
【第一层分析】测试用例问题 vs 代码问题
  ├─ 测试用例问题 → 修复测试用例 → 重新测试
  └─ 代码问题 ↓

【第二层分析】Bug（实现错误）vs 设计问题
  ├─ Bug（实现错误）→ 修复代码 → 重新测试
  └─ 设计问题 ↓

【第三层分析】架构问题 vs 需求问题
  ├─ 架构问题 → 需要修改架构设计
  └─ 需求问题 → 需要修改PRD

【AI建议回滚阶段】
  - requirements（需求问题）
  - architecture（架构问题）
  - implementation（Bug）
  ↓
【人工确认回滚阶段】
  ↓
【AI生成修复任务链】（自上而下）
  - 任务1: 修改PRD（如果是需求问题）→ 人工审批
  - 任务2: 修改架构文档 → 人工审批
  - 任务3: 修改代码 → AI实现
  ↓
【执行修复任务】
  ↓
【重新执行后续阶段】
```

---

## 六、Testing阶段的审批流程

Testing阶段包含3次独立的审批点，渐进式执行：

```
Testing阶段开始
  ↓
【审批点1：E2E测试】
  ├─ AI生成"E2E测试计划.md"
  ├─ 人工审批
  │   ├─ 通过 → AI生成测试代码 → 执行E2E测试
  │   └─ 拒绝 → AI根据意见重新生成测试计划
  ↓ (E2E测试通过)

【审批点2：性能测试】
  ├─ AI生成"性能测试方案.md"
  ├─ 人工审批
  │   ├─ 通过 → AI生成测试代码 → 执行性能测试
  │   └─ 拒绝 → AI根据意见重新生成测试方案
  ↓ (性能测试通过)

【审批点3：混沌测试】
  ├─ AI生成"混沌测试方案.md"
  ├─ 人工审批
  │   ├─ 通过 → AI生成测试代码 → 执行混沌测试
  │   └─ 拒绝 → AI根据意见重新生成测试方案
  ↓ (混沌测试通过)

Testing阶段完成
```

---

## 七、Git Commit策略

**详细规范**：参见 `.claude/guides/git-integration.md`

**Testing阶段特殊规则**：

| 阶段 | Type | Scope | 示例 |
|------|------|-------|------|
| **Implementation** | `feat` | 模块名 | `feat(用户模块): 实现getUserInfo + 测试` |
| **Testing (E2E)** | `test` | `e2e` | `test(e2e): 添加E2E测试` |
| **Testing (性能)** | `test` | `performance` | `test(performance): 添加性能测试` |
| **Testing (混沌)** | `test` | `chaos` | `test(chaos): 添加混沌测试` |

---

## 八、实践原则

### 1. 测试文档先行

```
✅ 正确做法（Testing阶段）：
- 先生成测试文档（E2E测试计划.md）
- 人工审批测试文档
- 再生成测试代码

❌ 错误做法：
- 直接生成测试代码
- 测试逻辑不符合用户预期
```

### 2. 覆盖率100%是底线

```
✅ 正确做法：
- Implementation阶段结束时，单元测试覆盖率必须100%
- 未达标则继续补充测试用例

❌ 错误做法：
- 覆盖率90%就进入Testing阶段
```

### 3. 测试失败必须找到根因

```
✅ 正确做法：
- 测试失败后，AI执行分层分析，找到真实根因
- 生成完整的根因分析报告
- 人工确认后再修复

❌ 错误做法：
- 测试失败后直接修改测试用例让它通过
- 掩盖真实问题
```

### 4. 渐进式测试执行

```
✅ 正确做法：
- E2E通过 → 性能通过 → 混沌通过
- 逐个测试类型执行和审批

❌ 错误做法：
- 同时生成所有测试文档
- 一次审批所有测试
```
